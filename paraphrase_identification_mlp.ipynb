{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f64a444c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7e91a131",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train_with_label.txt',sep='\\t',header=None,quoting=csv.QUOTE_NONE)\n",
    "df_test = pd.read_csv('dev_with_label.txt', sep='\\t',header=None,quoting=csv.QUOTE_NONE)\n",
    "df_test_nolabel = pd.read_csv('test_without_label.txt', sep='\\t',header=None,quoting=csv.QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "33782f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training datatset shape: (7801, 4)\n",
      "Test datatset shape: (4000, 4)\n",
      "Test no label datatset shape: (4000, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training datatset shape: \" + str(df_train.shape))\n",
    "print(\"Test datatset shape: \" + str(df_test.shape))\n",
    "print(\"Test no label datatset shape: \" + str(df_test_nolabel.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "07c0254c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting column names for test and training set\n",
    "df_train.columns = [\"instance_id\",\"sent1\",\"sent2\",\"gold_score\"]\n",
    "df_test.columns = [\"instance_id\",\"sent1\",\"sent2\",\"gold_score\"]\n",
    "df_test_nolabel.columns = [\"instance_id\",\"sent1\",\"sent2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "31099a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instance_id    0\n",
      "sent1          0\n",
      "sent2          0\n",
      "gold_score     0\n",
      "dtype: int64\n",
      "instance_id    0\n",
      "sent1          0\n",
      "sent2          0\n",
      "gold_score     0\n",
      "dtype: int64\n",
      "instance_id    0\n",
      "sent1          0\n",
      "sent2          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#check for null values and eliminate them\n",
    "print(df_train.isnull().sum())\n",
    "print(df_test.isnull().sum())\n",
    "print(df_test_nolabel.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "df4e0f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data target names: [0 1]\n",
      "Test data target names: [0 1]\n"
     ]
    }
   ],
   "source": [
    "#possible target names \n",
    "print(\"Train data target names: {}\".format(df_train[\"gold_score\"].unique()))\n",
    "print(\"Test data target names: {}\".format(df_test[\"gold_score\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "89bb5790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instance_id    object\n",
      "sent1          object\n",
      "sent2          object\n",
      "gold_score      int64\n",
      "dtype: object\n",
      "instance_id    object\n",
      "sent1          object\n",
      "sent2          object\n",
      "gold_score      int64\n",
      "dtype: object\n",
      "instance_id    object\n",
      "sent1          object\n",
      "sent2          object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_train.dtypes)\n",
    "print(df_test.dtypes)\n",
    "print(df_test_nolabel.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bfb46842",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training dataset\n",
    "df_train['sent1']=df_train['sent1'].astype('string')\n",
    "df_train['sent2']=df_train['sent2'].astype('string')\n",
    "df_train['sent1'] = df_train['sent1'].str.lower()\n",
    "df_train['sent2'] = df_train['sent2'].str.lower()\n",
    "#Test dataset\n",
    "df_test['sent1']=df_test['sent1'].astype('string')\n",
    "df_test['sent2']=df_test['sent2'].astype('string')\n",
    "df_test['sent1'] = df_test['sent1'].str.lower()\n",
    "df_test['sent2'] = df_test['sent2'].str.lower()\n",
    "#Test with no label\n",
    "df_test_nolabel['sent1']=df_test_nolabel['sent1'].astype('string')\n",
    "df_test_nolabel['sent2']=df_test_nolabel['sent2'].astype('string')\n",
    "df_test_nolabel['sent1'] = df_test_nolabel['sent1'].str.lower()\n",
    "df_test_nolabel['sent2'] = df_test_nolabel['sent2'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e47cc1b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instance_id    object\n",
      "sent1          string\n",
      "sent2          string\n",
      "gold_score      int64\n",
      "dtype: object\n",
      "instance_id    object\n",
      "sent1          string\n",
      "sent2          string\n",
      "gold_score      int64\n",
      "dtype: object\n",
      "instance_id    object\n",
      "sent1          string\n",
      "sent2          string\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_train.dtypes)\n",
    "print(df_test.dtypes)\n",
    "print(df_test_nolabel.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e9484a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training\n",
    "df_train['sent1'] = df_train['sent1'].str.replace(\",\",\"\")\n",
    "df_train['sent2'] = df_train['sent2'].str.replace(\",\",\"\")\n",
    "#Testing\n",
    "df_test['sent1'] = df_test['sent1'].str.replace(\",\",\"\")\n",
    "df_test['sent2'] = df_test['sent2'].str.replace(\",\",\"\")\n",
    "#Testing with no label\n",
    "df_test_nolabel['sent1'] = df_test_nolabel['sent1'].str.replace(\",\",\"\")\n",
    "df_test_nolabel['sent2'] = df_test_nolabel['sent2'].str.replace(\",\",\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85559e8b",
   "metadata": {},
   "source": [
    "## Feature1: Word count difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b7177f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training\n",
    "df_train['sent1_tok'] = df_train['sent1'].str.split()\n",
    "df_train['sent2_tok'] = df_train['sent2'].str.split()\n",
    "#Testing\n",
    "df_test['sent1_tok'] = df_test['sent1'].str.split()\n",
    "df_test['sent2_tok'] = df_test['sent2'].str.split()\n",
    "#Testing with no label\n",
    "df_test_nolabel['sent1_tok'] = df_test_nolabel['sent1'].str.split()\n",
    "df_test_nolabel['sent2_tok'] = df_test_nolabel['sent2'].str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a46bd80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training\n",
    "df_train['sent1l']=df_train['sent1_tok'].apply(lambda x: len(x))\n",
    "df_train['sent2l']=df_train['sent2_tok'].apply(lambda x: len(x))\n",
    "#Testing\n",
    "df_test['sent1l']=df_test['sent1_tok'].apply(lambda x: len(x))\n",
    "df_test['sent2l']=df_test['sent2_tok'].apply(lambda x: len(x))\n",
    "#Testing with no label\n",
    "df_test_nolabel['sent1l']=df_test_nolabel['sent1_tok'].apply(lambda x: len(x))\n",
    "df_test_nolabel['sent2l']=df_test_nolabel['sent2_tok'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "139b5ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.assign(wcd=lambda x: abs((x['sent1l']-x['sent2l'])))\n",
    "df_test = df_test.assign(wcd=lambda x: abs((x['sent1l']-x['sent2l'])))\n",
    "df_test_nolabel = df_test_nolabel.assign(wcd=lambda x: abs((x['sent1l']-x['sent2l'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8457cbf2",
   "metadata": {},
   "source": [
    "## Feature 2: Bleu Score (1,2 and 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bdaa495f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "from nltk import word_tokenize\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2c2fc11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['bleu_score'] = df_train.apply(lambda row: sentence_bleu(row['sent1'].translate(str.maketrans('', '', string.punctuation)), row['sent2'].translate(str.maketrans('', '', string.punctuation)),smoothing_function=SmoothingFunction().method4), axis = 1)\n",
    "df_test['bleu_score'] = df_test.apply(lambda row: sentence_bleu(row['sent1'].translate(str.maketrans('', '', string.punctuation)), row['sent2'].translate(str.maketrans('', '', string.punctuation)),smoothing_function=SmoothingFunction().method4),axis = 1)\n",
    "df_test_nolabel['bleu_score'] = df_test_nolabel.apply(lambda row: sentence_bleu(row['sent1'].translate(str.maketrans('', '', string.punctuation)), row['sent2'].translate(str.maketrans('', '', string.punctuation)),smoothing_function=SmoothingFunction().method4),axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a7c7df",
   "metadata": {},
   "source": [
    "## Feature 3: Fuzzy ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "28eb8b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "21210262",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['fuzz_ratio'] = df_train.apply(lambda row: fuzz.ratio(row['sent1'].translate(str.maketrans('', '', string.punctuation)), row['sent2'].translate(str.maketrans('', '', string.punctuation))), axis = 1)\n",
    "df_test['fuzz_ratio'] = df_test.apply(lambda row: fuzz.ratio(row['sent1'].translate(str.maketrans('', '', string.punctuation)), row['sent2'].translate(str.maketrans('', '', string.punctuation))), axis = 1)\n",
    "df_test_nolabel['fuzz_ratio'] = df_test_nolabel.apply(lambda row: fuzz.ratio(row['sent1'].translate(str.maketrans('', '', string.punctuation)), row['sent2'].translate(str.maketrans('', '', string.punctuation))), axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "33f3a3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['fuzz_token_sort_ratio'] = df_train.apply(lambda row: fuzz.token_sort_ratio(row['sent1'].translate(str.maketrans('', '', string.punctuation)), row['sent2'].translate(str.maketrans('', '', string.punctuation))), axis = 1)\n",
    "df_test['fuzz_token_sort_ratio'] = df_test.apply(lambda row: fuzz.token_sort_ratio(row['sent1'].translate(str.maketrans('', '', string.punctuation)), row['sent2'].translate(str.maketrans('', '', string.punctuation))), axis = 1)\n",
    "df_test_nolabel['fuzz_token_sort_ratio'] = df_test_nolabel.apply(lambda row: fuzz.token_sort_ratio(row['sent1'].translate(str.maketrans('', '', string.punctuation)), row['sent2'].translate(str.maketrans('', '', string.punctuation))), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf9e758",
   "metadata": {},
   "source": [
    "## Feature 4: Levenshtein distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ff372bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Levenshtein import distance as lev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d004e399",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['lev_dist'] = df_train.apply(lambda row: lev(row['sent1'].translate(str.maketrans('', '', string.punctuation)), row['sent2'].translate(str.maketrans('', '', string.punctuation))), axis = 1)\n",
    "df_test['lev_dist'] = df_test.apply(lambda row: lev(row['sent1'].translate(str.maketrans('', '', string.punctuation)), row['sent2'].translate(str.maketrans('', '', string.punctuation))), axis = 1)\n",
    "df_test_nolabel['lev_dist'] = df_test_nolabel.apply(lambda row: lev(row['sent1'].translate(str.maketrans('', '', string.punctuation)), row['sent2'].translate(str.maketrans('', '', string.punctuation))), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c50914",
   "metadata": {},
   "source": [
    "## Feature 5: NIST score (1,2, and 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "39da6a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.nist_score import sentence_nist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d145853",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['nist_score'] = df_train.apply(lambda row: sentence_nist(row['sent1'].translate(str.maketrans('', '', string.punctuation)), row['sent2'].translate(str.maketrans('', '', string.punctuation))), axis = 1)\n",
    "df_test['nist_score'] = df_test.apply(lambda row: sentence_nist(row['sent1'].translate(str.maketrans('', '', string.punctuation)), row['sent2'].translate(str.maketrans('', '', string.punctuation))),axis = 1)\n",
    "df_test_nolabel['nist_score'] = df_test_nolabel.apply(lambda row: sentence_nist(row['sent1'].translate(str.maketrans('', '', string.punctuation)), row['sent2'].translate(str.maketrans('', '', string.punctuation))),axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e04488dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instance_id               object\n",
      "sent1                     string\n",
      "sent2                     string\n",
      "gold_score                 int64\n",
      "sent1_tok                 object\n",
      "sent2_tok                 object\n",
      "sent1l                     int64\n",
      "sent2l                     int64\n",
      "wcd                        int64\n",
      "bleu_score               float64\n",
      "fuzz_ratio                 int64\n",
      "fuzz_token_sort_ratio      int64\n",
      "lev_dist                   int64\n",
      "dtype: object\n",
      "instance_id               object\n",
      "sent1                     string\n",
      "sent2                     string\n",
      "gold_score                 int64\n",
      "sent1_tok                 object\n",
      "sent2_tok                 object\n",
      "sent1l                     int64\n",
      "sent2l                     int64\n",
      "wcd                        int64\n",
      "bleu_score               float64\n",
      "fuzz_ratio                 int64\n",
      "fuzz_token_sort_ratio      int64\n",
      "lev_dist                   int64\n",
      "dtype: object\n",
      "instance_id               object\n",
      "sent1                     string\n",
      "sent2                     string\n",
      "sent1_tok                 object\n",
      "sent2_tok                 object\n",
      "sent1l                     int64\n",
      "sent2l                     int64\n",
      "wcd                        int64\n",
      "bleu_score               float64\n",
      "fuzz_ratio                 int64\n",
      "fuzz_token_sort_ratio      int64\n",
      "lev_dist                   int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_train.dtypes)\n",
    "print(df_test.dtypes)\n",
    "print(df_test_nolabel.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ab874570",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'list'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-72701680acee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# X_train_val = X_train_val.reshape(-1,1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mX_test_nolabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_nolabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    728\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    764\u001b[0m         \"\"\"\n\u001b[1;32m    765\u001b[0m         \u001b[0mfirst_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"n_samples_seen_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 766\u001b[0;31m         X = self._validate_data(X, accept_sparse=('csr', 'csc'),\n\u001b[0m\u001b[1;32m    767\u001b[0m                                 \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m                                 force_all_finite='allow-nan', reset=first_call)\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    419\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'no_validation'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    614\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    617\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order, like)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_asarray_with_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlike\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "X_train = df_train.drop(columns=['instance_id','sent1','sent2','gold_score','sent1l','sent2l']).values\n",
    "X_test = df_test.drop(columns=['instance_id','sent1','sent2','gold_score','sent1l','sent2l']).values\n",
    "y_train = df_train['gold_score'].values\n",
    "y_test =df_test['gold_score'].values\n",
    "X_test_nolabel = df_test_nolabel.drop(columns=['instance_id','sent1','sent2','sent1l','sent2l']).values\n",
    "\n",
    "normalizer = StandardScaler()\n",
    "# X_train_val = X_train_val.reshape(-1,1)\n",
    "X_test = X_test.reshape(-1,1)\n",
    "X_train = normalizer.fit_transform(X_train)\n",
    "X_test = normalizer.transform(X_test)\n",
    "X_test_nolabel = normalizer.transform(X_test_nolabel)\n",
    "print(\"train_val: {}, test: {}, test_nolabel: {}\".format(X_train.shape, X_test.shape, X_test_nolabel.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56563d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272633e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clfmlp = MLPClassifier(hidden_layer_sizes=(6,5),\n",
    "                    random_state=5,\n",
    "                    verbose=True,\n",
    "                    learning_rate_init=0.01)\n",
    "\n",
    "clfmlp.fit(X_train, y_train)\n",
    "y_test_pred = clfmlp.predict(X_test)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "acc = accuracy_score(y_test, y_test_pred)\n",
    "print(\"F1 score: {:.3f}, Accuracy: {:.3f}\".format(f1,acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d41fa4",
   "metadata": {},
   "source": [
    "## Prediction for test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f512252",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = clfmp.predict(X_test_nolabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0a480f",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = df_test_nolabel['instance_id'].to_numpy()\n",
    "# print(dt)\n",
    "print(len(iterations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7bf26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(y_test_pred)\n",
    "print(len(y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db247da",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('AbuHasnatHasib_test_result.txt', 'w') #write to file\n",
    "count = 0\n",
    "for i in range(0,len(iterations)):\n",
    "    file.write(str(iterations[i]) + \"\\t\" + str(y_test_pred[i]) + \"\\n\")\n",
    "    count+=1\n",
    "print(\"Total number of test instances for the test result is : \" + str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35890107",
   "metadata": {},
   "outputs": [],
   "source": [
    "file.close() #close file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
