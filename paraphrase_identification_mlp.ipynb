{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f64a444c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7e91a131",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train_with_label.txt',sep='\\t',header=None,quoting=csv.QUOTE_NONE)\n",
    "df_test = pd.read_csv('dev_with_label.txt', sep='\\t',header=None,quoting=csv.QUOTE_NONE)\n",
    "df_test_nolabel = pd.read_csv('test_without_label.txt', sep='\\t',header=None,quoting=csv.QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "33782f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training datatset shape: (7801, 4)\n",
      "Test datatset shape: (4000, 4)\n",
      "Test no label datatset shape: (4000, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training datatset shape: \" + str(df_train.shape))\n",
    "print(\"Test datatset shape: \" + str(df_test.shape))\n",
    "print(\"Test no label datatset shape: \" + str(df_test_nolabel.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "07c0254c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting column names for test and training set\n",
    "df_train.columns = [\"instance_id\",\"sent1\",\"sent2\",\"gold_score\"]\n",
    "df_test.columns = [\"instance_id\",\"sent1\",\"sent2\",\"gold_score\"]\n",
    "df_test_nolabel.columns = [\"instance_id\",\"sent1\",\"sent2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "31099a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instance_id    0\n",
      "sent1          0\n",
      "sent2          0\n",
      "gold_score     0\n",
      "dtype: int64\n",
      "instance_id    0\n",
      "sent1          0\n",
      "sent2          0\n",
      "gold_score     0\n",
      "dtype: int64\n",
      "instance_id    0\n",
      "sent1          0\n",
      "sent2          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#check for null values and eliminate them\n",
    "print(df_train.isnull().sum())\n",
    "print(df_test.isnull().sum())\n",
    "print(df_test_nolabel.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "df4e0f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data target names: [0 1]\n",
      "Test data target names: [0 1]\n"
     ]
    }
   ],
   "source": [
    "#possible target names \n",
    "print(\"Train data target names: {}\".format(df_train[\"gold_score\"].unique()))\n",
    "print(\"Test data target names: {}\".format(df_test[\"gold_score\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "89bb5790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instance_id    object\n",
      "sent1          object\n",
      "sent2          object\n",
      "gold_score      int64\n",
      "dtype: object\n",
      "instance_id    object\n",
      "sent1          object\n",
      "sent2          object\n",
      "gold_score      int64\n",
      "dtype: object\n",
      "instance_id    object\n",
      "sent1          object\n",
      "sent2          object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_train.dtypes)\n",
    "print(df_test.dtypes)\n",
    "print(df_test_nolabel.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bfb46842",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training dataset\n",
    "df_train['sent1']=df_train['sent1'].astype('string')\n",
    "df_train['sent2']=df_train['sent2'].astype('string')\n",
    "df_train['sent1'] = df_train['sent1'].str.lower()\n",
    "df_train['sent2'] = df_train['sent2'].str.lower()\n",
    "#Test dataset\n",
    "df_test['sent1']=df_test['sent1'].astype('string')\n",
    "df_test['sent2']=df_test['sent2'].astype('string')\n",
    "df_test['sent1'] = df_test['sent1'].str.lower()\n",
    "df_test['sent2'] = df_test['sent2'].str.lower()\n",
    "#Test with no label\n",
    "df_test_nolabel['sent1']=df_test_nolabel['sent1'].astype('string')\n",
    "df_test_nolabel['sent2']=df_test_nolabel['sent2'].astype('string')\n",
    "df_test_nolabel['sent1'] = df_test_nolabel['sent1'].str.lower()\n",
    "df_test_nolabel['sent2'] = df_test_nolabel['sent2'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e47cc1b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instance_id    object\n",
      "sent1          string\n",
      "sent2          string\n",
      "gold_score      int64\n",
      "dtype: object\n",
      "instance_id    object\n",
      "sent1          string\n",
      "sent2          string\n",
      "gold_score      int64\n",
      "dtype: object\n",
      "instance_id    object\n",
      "sent1          string\n",
      "sent2          string\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_train.dtypes)\n",
    "print(df_test.dtypes)\n",
    "print(df_test_nolabel.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e9484a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training\n",
    "df_train['sent1'] = df_train['sent1'].str.replace(\",\",\"\")\n",
    "df_train['sent2'] = df_train['sent2'].str.replace(\",\",\"\")\n",
    "#Testing\n",
    "df_test['sent1'] = df_test['sent1'].str.replace(\",\",\"\")\n",
    "df_test['sent2'] = df_test['sent2'].str.replace(\",\",\"\")\n",
    "#Testing with no label\n",
    "df_test_nolabel['sent1'] = df_test_nolabel['sent1'].str.replace(\",\",\"\")\n",
    "df_test_nolabel['sent2'] = df_test_nolabel['sent2'].str.replace(\",\",\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85559e8b",
   "metadata": {},
   "source": [
    "## Feature1: Word count difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b7177f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training\n",
    "df_train['sent1l'] = df_train['sent1'].str.split()\n",
    "df_train['sent2l'] = df_train['sent2'].str.split()\n",
    "#Testing\n",
    "df_test['sent1l'] = df_test['sent1'].str.split()\n",
    "df_test['sent2l'] = df_test['sent2'].str.split()\n",
    "#Testing with no label\n",
    "df_test_nolabel['sent1l'] = df_test_nolabel['sent1'].str.split()\n",
    "df_test_nolabel['sent2l'] = df_test_nolabel['sent2'].str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a46bd80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training\n",
    "df_train['sent1l']=df_train['sent1l'].apply(lambda x: len(x))\n",
    "df_train['sent2l']=df_train['sent2l'].apply(lambda x: len(x))\n",
    "#Testing\n",
    "df_test['sent1l']=df_test['sent1l'].apply(lambda x: len(x))\n",
    "df_test['sent2l']=df_test['sent2l'].apply(lambda x: len(x))\n",
    "#Testing with no label\n",
    "df_test_nolabel['sent1l']=df_test_nolabel['sent1'].apply(lambda x: len(x))\n",
    "df_test_nolabel['sent2l']=df_test_nolabel['sent2'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "139b5ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.assign(wcd=lambda x: abs((x['sent1l']-x['sent2l'])))\n",
    "df_test = df_test.assign(wcd=lambda x: abs((x['sent1l']-x['sent2l'])))\n",
    "df_test_nolabel = df_test_nolabel.assign(wcd=lambda x: abs((x['sent1l']-x['sent2l'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a7c7df",
   "metadata": {},
   "source": [
    "## Feature 2: Fuzzy ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e0b11339",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d4a0f271",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['fuzz_ratio'] = df_train.apply(lambda row: fuzz.ratio(row['sent1'].translate(str.maketrans('', '', string.punctuation)), row['sent2'].translate(str.maketrans('', '', string.punctuation))), axis = 1)\n",
    "df_test['fuzz_ratio'] = df_test.apply(lambda row: fuzz.ratio(row['sent1'].translate(str.maketrans('', '', string.punctuation)), row['sent2'].translate(str.maketrans('', '', string.punctuation))), axis = 1)\n",
    "df_test_nolabel['fuzz_ratio'] = df_test_nolabel.apply(lambda row: fuzz.ratio(row['sent1'].translate(str.maketrans('', '', string.punctuation)), row['sent2'].translate(str.maketrans('', '', string.punctuation))), axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0a93b6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['fuzz_token_sort_ratio'] = df_train.apply(lambda row: fuzz.token_sort_ratio(row['sent1'].translate(str.maketrans('', '', string.punctuation)), row['sent2'].translate(str.maketrans('', '', string.punctuation))), axis = 1)\n",
    "df_test['fuzz_token_sort_ratio'] = df_test.apply(lambda row: fuzz.token_sort_ratio(row['sent1'].translate(str.maketrans('', '', string.punctuation)), row['sent2'].translate(str.maketrans('', '', string.punctuation))), axis = 1)\n",
    "df_test_nolabel['fuzz_token_sort_ratio'] = df_test_nolabel.apply(lambda row: fuzz.token_sort_ratio(row['sent1'].translate(str.maketrans('', '', string.punctuation)), row['sent2'].translate(str.maketrans('', '', string.punctuation))), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf9e758",
   "metadata": {},
   "source": [
    "## Feature 3: Levenshtein distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7c0c3bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Levenshtein import distance as lev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "65b35302",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['lev_dist'] = df_train.apply(lambda row: lev(row['sent1'].translate(str.maketrans('', '', string.punctuation)), row['sent2'].translate(str.maketrans('', '', string.punctuation))), axis = 1)\n",
    "df_test['lev_dist'] = df_test.apply(lambda row: lev(row['sent1'].translate(str.maketrans('', '', string.punctuation)), row['sent2'].translate(str.maketrans('', '', string.punctuation))), axis = 1)\n",
    "df_test_nolabel['lev_dist'] = df_test_nolabel.apply(lambda row: lev(row['sent1'].translate(str.maketrans('', '', string.punctuation)), row['sent2'].translate(str.maketrans('', '', string.punctuation))), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43392a0",
   "metadata": {},
   "source": [
    "## Feature 4: Bleu Score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cfd83e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2a04f245",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['bleu_score'] = df_train.apply(lambda row: sentence_bleu(row['sent1'].translate(str.maketrans('', '', string.punctuation)), row['sent2'].translate(str.maketrans('', '', string.punctuation)),smoothing_function=SmoothingFunction().method4), axis = 1)\n",
    "df_test['bleu_score'] = df_test.apply(lambda row: sentence_bleu(row['sent1'].translate(str.maketrans('', '', string.punctuation)), row['sent2'].translate(str.maketrans('', '', string.punctuation)),smoothing_function=SmoothingFunction().method4),axis = 1)\n",
    "df_test_nolabel['bleu_score'] = df_test_nolabel.apply(lambda row: sentence_bleu(row['sent1'].translate(str.maketrans('', '', string.punctuation)), row['sent2'].translate(str.maketrans('', '', string.punctuation)),smoothing_function=SmoothingFunction().method4),axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607fc94c",
   "metadata": {},
   "source": [
    "## Feature 5: NIST score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "aaf624ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.nist_score import sentence_nist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "785bb9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['nist_score'] = df_train.apply(lambda row: sentence_nist(row['sent1'].translate(str.maketrans('', '', string.punctuation)), row['sent2'].translate(str.maketrans('', '', string.punctuation))), axis = 1)\n",
    "df_test['nist_score'] = df_test.apply(lambda row: sentence_nist(row['sent1'].translate(str.maketrans('', '', string.punctuation)), row['sent2'].translate(str.maketrans('', '', string.punctuation))),axis = 1)\n",
    "df_test_nolabel['nist_score'] = df_test_nolabel.apply(lambda row: sentence_nist(row['sent1'].translate(str.maketrans('', '', string.punctuation)), row['sent2'].translate(str.maketrans('', '', string.punctuation))),axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e04488dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instance_id               object\n",
      "sent1                     string\n",
      "sent2                     string\n",
      "gold_score                 int64\n",
      "sent1l                     int64\n",
      "sent2l                     int64\n",
      "wcd                        int64\n",
      "fuzz_ratio                 int64\n",
      "fuzz_token_sort_ratio      int64\n",
      "lev_dist                   int64\n",
      "bleu_score               float64\n",
      "nist_score               float64\n",
      "dtype: object\n",
      "instance_id               object\n",
      "sent1                     string\n",
      "sent2                     string\n",
      "gold_score                 int64\n",
      "sent1l                     int64\n",
      "sent2l                     int64\n",
      "wcd                        int64\n",
      "fuzz_ratio                 int64\n",
      "fuzz_token_sort_ratio      int64\n",
      "lev_dist                   int64\n",
      "bleu_score               float64\n",
      "nist_score               float64\n",
      "dtype: object\n",
      "instance_id               object\n",
      "sent1                     string\n",
      "sent2                     string\n",
      "sent1l                     int64\n",
      "sent2l                     int64\n",
      "wcd                        int64\n",
      "fuzz_ratio                 int64\n",
      "fuzz_token_sort_ratio      int64\n",
      "lev_dist                   int64\n",
      "bleu_score               float64\n",
      "nist_score               float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_train.dtypes)\n",
    "print(df_test.dtypes)\n",
    "print(df_test_nolabel.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ab874570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_val: (7801, 6), test: (4000, 6), test_nolabel: (4000, 6)\n"
     ]
    }
   ],
   "source": [
    "X_train = df_train.drop(columns=['instance_id','sent1','sent2','gold_score','sent1l','sent2l']).values\n",
    "X_test = df_test.drop(columns=['instance_id','sent1','sent2','gold_score','sent1l','sent2l']).values\n",
    "y_train = df_train['gold_score'].values\n",
    "y_test =df_test['gold_score'].values\n",
    "X_test_nolabel = df_test_nolabel.drop(columns=['instance_id','sent1','sent2','sent1l','sent2l']).values\n",
    "\n",
    "normalizer = StandardScaler()\n",
    "# X_train_val = X_train_val.reshape(-1,1)\n",
    "# X_test = X_test.reshape(-1,1)\n",
    "X_train = normalizer.fit_transform(X_train)\n",
    "X_test = normalizer.transform(X_test)\n",
    "X_test_nolabel = normalizer.transform(X_test_nolabel)\n",
    "print(\"train_val: {}, test: {}, test_nolabel: {}\".format(X_train.shape, X_test.shape, X_test_nolabel.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9125e963",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "56563d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "272633e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.798, Accuracy: 0.893\n"
     ]
    }
   ],
   "source": [
    "clfmlp = MLPClassifier(hidden_layer_sizes=(8,7),\n",
    "                    random_state=5,\n",
    "                    verbose=False,\n",
    "                    learning_rate_init=0.01)\n",
    "\n",
    "clfmlp.fit(X_train, y_train)\n",
    "y_test_pred = clfmlp.predict(X_test)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "acc = accuracy_score(y_test, y_test_pred)\n",
    "print(\"F1 score: {:.3f}, Accuracy: {:.3f}\".format(f1,acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e95c7e",
   "metadata": {},
   "source": [
    "## Prediction for test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7f512252",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = clfmlp.predict(X_test_nolabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "10e173ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n"
     ]
    }
   ],
   "source": [
    "iterations = df_test_nolabel['instance_id'].to_numpy()\n",
    "# print(dt)\n",
    "print(len(iterations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5515caae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n"
     ]
    }
   ],
   "source": [
    "# print(y_test_pred)\n",
    "print(len(y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "48921ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of test instances for the test result is : 4000\n"
     ]
    }
   ],
   "source": [
    "file = open('AbuHasnatHasib_test_result.txt', 'w') #write to file\n",
    "count = 0\n",
    "for i in range(0,len(iterations)):\n",
    "    file.write(str(iterations[i]) + \"\\t\" + str(y_test_pred[i]) + \"\\n\")\n",
    "    count+=1\n",
    "print(\"Total number of test instances for the test result is : \" + str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c2469948",
   "metadata": {},
   "outputs": [],
   "source": [
    "file.close() #close file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74212a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
